{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文章相似度算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过计算文章的相似度，来进行文字的伪原创，实现文章的批量添加和新闻，中标详情页的收录率的提高。  \n",
    "数据说明：doc2-doc5.txt为样本文档，doc1为测试文档"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要用到的包如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora,models,similarities\n",
    "from jieba import posseg\n",
    "import jieba\n",
    "import urllib.request\n",
    "from collections import defaultdict\n",
    "\n",
    "test_file_name=\"doc1.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**读取样本文件**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共读取了 5 篇文章。\n"
     ]
    }
   ],
   "source": [
    "docs=[]\n",
    "for i in range(1,6):\n",
    "    filename=\"doc\"+str(i)+\".txt\"\n",
    "    f=open(filename,mode=\"r\",encoding=\"utf-8\")\n",
    "    content=f.read()\n",
    "    docs.append(content)\n",
    "    f.close()\n",
    "print(\"共读取了 \" + str(len(docs)) + \" 篇文章。\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分词并删除停止词**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 读取停止词词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取到停止词：2321\n"
     ]
    }
   ],
   "source": [
    "def readStopWord(filelist):\n",
    "    stop_word=set()\n",
    "    for file in filelist:\n",
    "        for line in open(file,mode=\"r\",encoding=\"gbk\"):\n",
    "            stop_word.add(line)\n",
    "    return stop_word\n",
    "\n",
    "filelist=[\"百度停用词列表.txt\",\"哈工大停用词表.txt\",\"四川大学机器智能实验室停用词库.txt\",\"中文停用词库.txt\",\"自己的停止词词库.txt\"]\n",
    "stop_word=readStopWord(filelist)\n",
    "print(\"读取到停止词：\" + str(len(stop_word))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分词**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分词并删除停止词\n",
    "def cut_word(docs,stop_word):\n",
    "    del_flag_word=set(['x','uj','v','r','y','zg','c','p','c','m','d'])\n",
    "    docs_words=[]\n",
    "    set_docs_words=set()\n",
    "    for doc in docs:\n",
    "        doc_words=posseg.cut(doc)\n",
    "        doc_words=[word for word in doc_words if word.flag not in del_flag_word]\n",
    "        doc_words=[word for word in doc_words if word.word not in stop_word]\n",
    "        doc_words=[word.word for word in doc_words]\n",
    "        docs_words.append(doc_words)\n",
    "        for word in doc_words:\n",
    "            set_docs_words.add(word)\n",
    "    return docs_words,set_docs_words\n",
    "all_doc_words,set_docs_words=cut_word(docs,stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 183)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_doc_words[0]),len(set_docs_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**读取测试文档** \n",
    "  ###### 读取测试文档，对测试文档进行分词，生成测试文档分词列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=open(test_file_name,mode=\"r\",encoding=\"utf-8\")\n",
    "doc1=f.read()\n",
    "f.close()\n",
    "test_doc_words,test_set_docs_words=cut_word([doc1],stop_word)\n",
    "test_doc_words=test_doc_words[0]\n",
    "len(test_doc_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 制作语料库 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先用dictionary方法获取词袋（bag-of-words)\n",
    "dictionary=corpora.Dictionary(all_doc_words)\n",
    "\n",
    "#词袋中用数字对所有词进行了编号\n",
    "dictionary.keys()\n",
    "\n",
    "#编号与词之间的对应关系\n",
    "dictionary.token2id\n",
    "\n",
    "#使用doc2bow制作语料库\n",
    "corpus = [dictionary.doc2bow(doc_words) for doc_words in all_doc_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对测试文档分词转换为二元向量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_test_vec = dictionary.doc2bow(test_doc_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**相似度分析**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docindex:0  sim：1.0   结果判定：相似\n",
      "docindex:3  sim：0.40909374   结果判定：相似\n",
      "docindex:2  sim：0.3548258   结果判定：相似\n",
      "docindex:1  sim：0.14954704   结果判定：不相似\n",
      "docindex:4  sim：0.12729307   结果判定：不相似\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1.0), (3, 0.40909374), (2, 0.3548258), (1, 0.14954704), (4, 0.12729307)]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用TF-IDF模型对语料库建模\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "#获取测试文档中，每个词的TF-IDF值\n",
    "tfidf[doc_test_vec]\n",
    "\n",
    "#对每个目标文档，分析测试文档的相似度\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=len(dictionary.keys()))\n",
    "sim = index[tfidf[doc_test_vec]]\n",
    "sim\n",
    "\n",
    "#根据相似度排序\n",
    "result=sorted(enumerate(sim), key=lambda item: -item[1])\n",
    "for r in result:\n",
    "    docindex,s=r\n",
    "    if s >0.2:\n",
    "        msg=\"相似\"\n",
    "    else:\n",
    "        msg=\"不相似\"\n",
    "    print(\"docindex:\"+str(docindex)+\"  sim：\"+str(s)  +\"   结果判定：\"+msg)\n",
    "result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
